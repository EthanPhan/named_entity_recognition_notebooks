{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Interpretable Named Entity Recognition With Keras And LIME",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsigAOmELNLj",
        "colab_type": "text"
      },
      "source": [
        "### What does explainable mean?\n",
        "Deep neural networks are quite successful in many use-cases, but these models can be hard to debug and to understand what’s going on. Our aim is to understand how much certain words influence the prediction of our named entity tagger. We want a human-understandable qualitative explanation which enables an interpretation of the underlying algorithm."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPr1GzjjLSoe",
        "colab_type": "text"
      },
      "source": [
        "### Data preperation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3DcxoiLLO73",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7f0ad36d-670c-44df-9c8c-013974068546"
      },
      "source": [
        "import os\n",
        "from urllib.request import urlretrieve\n",
        "import zipfile\n",
        "import glob\n",
        "\n",
        "if not os.path.exists('data'):\n",
        "    os.makedirs('data')\n",
        "    \n",
        "# Download data\n",
        "url ='https://storage.googleapis.com/kaggle-datasets/1014/4361/entity-annotated-corpus.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1568009584&Signature=hSdo87OA6a0gwPDkkK1eHg1l3bfLg%2FO9CTZ%2Fma6B%2F%2BmcwwU7OQiEmjKpgJ8ROWbPXrwjhED3u3dkas63MRbL1Rin3XUeWKU3y6TqgK%2FmleA3SVf6jBqXTOfRjyDaPXPNYdJLYFCWIDbygZPxoNEmXel3ZV%2B3MQgDOKH%2FzAP1NLuU5y6VHaFePdsruHAb1KICRY6qvsl5gFTYyBkJw3xO0qoF8oNkG3C4uUDaTEaqVK7FOfAw7OkkpTXqc9GtjUdsI3Dr11QNYgTmIOdreqk0fgr89QaenXBTfZlS8hqMu46Ik1VrX0Y5zfOSH7Rd3T5ltDvNNANlh%2FA%2BpJr0y16cHA%3D%3D'\n",
        "\n",
        "urlretrieve(url, 'data/kaggle_ner.zip')\n",
        "\n",
        "with zipfile.ZipFile('data/kaggle_ner.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('data/')\n",
        "    \n",
        "import glob\n",
        "\n",
        "glob.glob('data/*')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['data/kaggle_ner.zip', 'data/ner.csv', 'data/ner_dataset.csv']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtCoHEbQLXE2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cd014b94-716b-4e97-b830-fd5a216065c4"
      },
      "source": [
        "import pandas as pd    \n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "data = pd.read_csv(\"data/ner_dataset.csv\", encoding=\"latin1\")\n",
        "data = data.fillna(method=\"ffill\")\n",
        "\n",
        "class SentenceGetter(object):\n",
        "    def __init__(self, data):\n",
        "        self.n_sent = 1\n",
        "        self.data = data\n",
        "        self.empty = False\n",
        "        agg_func = lambda s: [(w, p, t) for w, p, t in zip(s[\"Word\"].values.tolist(),\n",
        "                                                           s[\"POS\"].values.tolist(),\n",
        "                                                           s[\"Tag\"].values.tolist())]\n",
        "        self.grouped = self.data.groupby(\"Sentence #\").apply(agg_func)\n",
        "        self.sentences = [s for s in self.grouped]\n",
        "    \n",
        "    def get_next(self):\n",
        "        try:\n",
        "            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n",
        "            self.n_sent += 1\n",
        "            return s\n",
        "        except:\n",
        "            return None\n",
        "        \n",
        "getter = SentenceGetter(data)\n",
        "sentences = getter.sentences\n",
        "\n",
        "max_len = 50\n",
        "max_len_char = 10\n",
        "\n",
        "words = list(set(data[\"Word\"].values))\n",
        "n_words = len(words)\n",
        "\n",
        "tags = list(set(data[\"Tag\"].values))\n",
        "n_tags = len(tags); n_tags\n",
        "tag2idx = {t: i for i, t in enumerate(tags)}\n",
        "\n",
        "labels = [[s[2] for s in sent] for sent in sentences]\n",
        "sentences = [\" \".join([s[0] for s in sent]) for sent in sentences]\n",
        "sentences[0]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Thousands of demonstrators have marched through London to protest the war in Iraq and demand the withdrawal of British troops from that country .'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67irv_o8LZ_m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_cnt = Counter(data[\"Word\"].values)\n",
        "vocabulary = set(w[0] for w in word_cnt.most_common(5000))\n",
        "\n",
        "word2idx = {\"PAD\": 0, \"UNK\": 1}\n",
        "word2idx.update({w: i for i, w in enumerate(words) if w in vocabulary})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "camSTdKnObiz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "\n",
        "X = [[word2idx.get(w, word2idx[\"UNK\"]) for w in s.split()] for s in sentences]\n",
        "X = pad_sequences(maxlen=max_len, sequences=X, padding=\"post\", value=word2idx[\"PAD\"])\n",
        "\n",
        "y = [[tag2idx[l_i] for l_i in l] for l in labels]\n",
        "y = pad_sequences(maxlen=max_len, sequences=y, padding=\"post\", value=tag2idx[\"O\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLHg4T7HO0pX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.1, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbdGWrvUO7MT",
        "colab_type": "text"
      },
      "source": [
        "### Setup The NER Model\n",
        "We use the simple LSTM model. But the procedure shown here applies to all kinds of sequence models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuTKI1k_O4d3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "99734dea-73c4-41b8-a8ea-dfec518cf309"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Conv1D, Lambda\n",
        "from tensorflow.keras.layers import Bidirectional, concatenate, SpatialDropout1D, GlobalMaxPooling1D, add\n",
        "\n",
        "word_input = Input(shape=(max_len,))\n",
        "\n",
        "# Instantiate the custom Bert Layer defined above\n",
        "embedding = Embedding(input_dim=n_words, output_dim=50, input_length=max_len)(word_input)\n",
        "\n",
        "x = Bidirectional(LSTM(units=256, return_sequences=True,\n",
        "                       recurrent_dropout=0.2, dropout=0.2))(embedding)\n",
        "\n",
        "out = TimeDistributed(Dense(n_tags, activation=\"softmax\"))(x)\n",
        "\n",
        "\n",
        "model = Model(word_input, out)\n",
        "\n",
        "adam = tf.keras.optimizers.Adam(clipnorm = 1.)\n",
        "model.compile(optimizer=adam, loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 50)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      (None, 50, 50)            1758900   \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 50, 512)           628736    \n",
            "_________________________________________________________________\n",
            "time_distributed_1 (TimeDist (None, 50, 17)            8721      \n",
            "=================================================================\n",
            "Total params: 2,396,357\n",
            "Trainable params: 2,396,357\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EheJHYclPenY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "af0280c9-fe16-42d5-854c-d575b8b1bef5"
      },
      "source": [
        "history = model.fit(X_tr, y_tr.reshape(*y_tr.shape, 1),\n",
        "                    batch_size=32, epochs=5,\n",
        "                    validation_split=0.1, verbose=1)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 38846 samples, validate on 4317 samples\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Epoch 1/5\n",
            "38846/38846 [==============================] - 444s 11ms/sample - loss: 0.1584 - acc: 0.9612 - val_loss: 0.0704 - val_acc: 0.9795\n",
            "Epoch 2/5\n",
            "38846/38846 [==============================] - 440s 11ms/sample - loss: 0.0634 - acc: 0.9808 - val_loss: 0.0585 - val_acc: 0.9826\n",
            "Epoch 3/5\n",
            "38846/38846 [==============================] - 448s 12ms/sample - loss: 0.0550 - acc: 0.9828 - val_loss: 0.0562 - val_acc: 0.9829\n",
            "Epoch 4/5\n",
            "38846/38846 [==============================] - 446s 11ms/sample - loss: 0.0506 - acc: 0.9839 - val_loss: 0.0539 - val_acc: 0.9835\n",
            "Epoch 5/5\n",
            "38846/38846 [==============================] - 442s 11ms/sample - loss: 0.0477 - acc: 0.9847 - val_loss: 0.0531 - val_acc: 0.9839\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FF3K9DLTDnB",
        "colab_type": "text"
      },
      "source": [
        "### Now Look At The Predictions And Explain Them\n",
        "\n",
        "To explain the predictions, we use the LIME algorithm implemented in the eli5 library. We assume you already now what the algorithm is doing. You can read more about it in [this post](https://www.depends-on-the-definition.com/debugging-black-box-text-classifiers-with-lime/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avmSQrtyPpXs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "f28acc96-4164-4f18-fd13-e8b06eb09ad2"
      },
      "source": [
        "!pip install eli5\n",
        "from eli5.lime import TextExplainer\n",
        "from eli5.lime.samplers import MaskingTextSampler"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting eli5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/97/2f/c85c7d8f8548e460829971785347e14e45fa5c6617da374711dec8cb38cc/eli5-0.10.1-py2.py3-none-any.whl (105kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 3.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from eli5) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from eli5) (1.16.5)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.6/dist-packages (from eli5) (0.21.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from eli5) (2.10.1)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from eli5) (0.10.1)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.6/dist-packages (from eli5) (0.8.3)\n",
            "Requirement already satisfied: attrs>16.0.0 in /usr/local/lib/python3.6/dist-packages (from eli5) (19.1.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from eli5) (1.3.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.18->eli5) (0.13.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->eli5) (1.1.1)\n",
            "Installing collected packages: eli5\n",
            "Successfully installed eli5-0.10.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01ft6w8qTVzf",
        "colab_type": "text"
      },
      "source": [
        "Now we create a small python class, that holds our preprocessing and prediction of the model. To apply LIME we just need a function to make predictions on texts. We use the closure pattern in `get_predict_function` which returns a function that takes a list of texts, processes them and returns the predictions of our previously trained model.\n",
        "\n",
        "### The trick\n",
        "To make the LIME algorithm work for us, we need to rephrase our problem as a simple multi-class classification problem. We do this by selecting before-hand for which word we want to explain the prediction. This is done by passing the `word_index` to the `get_predict_function` method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLEGRZB1TQQD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NERExplainerGenerator(object):\n",
        "    \n",
        "    def __init__(self, model, word2idx, tag2idx, max_len):\n",
        "        self.model = model\n",
        "        self.word2idx = word2idx\n",
        "        self.tag2idx = tag2idx\n",
        "        self.idx2tag = {v: k for k,v in tag2idx.items()}\n",
        "        self.max_len = max_len\n",
        "        \n",
        "    def _preprocess(self, texts):\n",
        "        X = [[self.word2idx.get(w, self.word2idx[\"UNK\"]) for w in t.split()]\n",
        "             for t in texts]\n",
        "        X = pad_sequences(maxlen=self.max_len, sequences=X,\n",
        "                          padding=\"post\", value=self.word2idx[\"PAD\"])\n",
        "        return X\n",
        "    \n",
        "    def get_predict_function(self, word_index):\n",
        "        def predict_func(texts):\n",
        "            X = self._preprocess(texts)\n",
        "            p = self.model.predict(X)\n",
        "            return p[:,word_index,:]\n",
        "        return predict_func"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRj6tRj2YjfF",
        "colab_type": "text"
      },
      "source": [
        "Let’s have a look at some interesting samples. For example the 46781th text in our data set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlVg_jbWYgW7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "7ad7a291-8abd-468e-d536-5af5e42673b1"
      },
      "source": [
        "index = 46781\n",
        "label = labels[index]\n",
        "text = sentences[index]\n",
        "print(text)\n",
        "print()\n",
        "print(\" \".join([f\"{t} ({l})\" for t, l in zip(text.split(), label)]))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Nigeria 's President Olusegun Obasanjo expressed his condolences , noting the late pontiff promoted religious tolerance and democracy in the West African nation .\n",
            "\n",
            "Nigeria (B-geo) 's (O) President (B-per) Olusegun (I-per) Obasanjo (I-per) expressed (O) his (O) condolences (O) , (O) noting (O) the (O) late (O) pontiff (O) promoted (O) religious (O) tolerance (O) and (O) democracy (O) in (O) the (O) West (O) African (B-gpe) nation (O) . (O)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gaxPu_i6YzeF",
        "colab_type": "text"
      },
      "source": [
        "Now start to explain the prediction. We first initialize our generator object."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFUmbp9TYpzy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "explainer_generator = NERExplainerGenerator(model, word2idx, tag2idx, max_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H91eEkxtY2NL",
        "colab_type": "text"
      },
      "source": [
        "We want to explain the NER prediction for the word “Obasanjo”, so we pick word_index=4 and generate the respective prediction function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CuXqnYOwY1iQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_index = 4\n",
        "predict_func = explainer_generator.get_predict_function(word_index=word_index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykX4HZ2aY7gb",
        "colab_type": "text"
      },
      "source": [
        "Here we have to specify a sampler for the LIME algorithm. This controls how the algorithm samples perturbed samples from the text we want to explain. Read more about this in this article or the eli5 documentation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "otSSaHyGY67f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "1acf9cd1-1670-44ca-b8d5-04ec89745ccd"
      },
      "source": [
        "sampler = MaskingTextSampler(\n",
        "    replacement=\"UNK\",\n",
        "    max_replace=0.7,\n",
        "    token_pattern=None,\n",
        "    bow=False\n",
        ")\n",
        "\n",
        "samples, similarity = sampler.sample_near(text, n_samples=4)\n",
        "print(samples)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(\"Nigeria 'UNK President Olusegun Obasanjo expressed his condolences , noting the late pontiff promoted UNK UNK and democracy in the West African UNK .\", \"Nigeria 's President Olusegun Obasanjo expressed his condolences , noting the late UNK promoted religious tolerance and UNK in UNK West African nation .\", \"Nigeria 's UNK UNK UNK expressed UNK UNK , UNK UNK late pontiff promoted religious tolerance UNK democracy UNK UNK UNK UNK nation .\", \"UNK 'UNK UNK Olusegun UNK expressed his condolences , noting UNK late pontiff UNK religious tolerance and UNK in UNK UNK African nation .\")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77cazAEIZI-G",
        "colab_type": "text"
      },
      "source": [
        "Finally, we set up the `TextExplainer` and explain the prediction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCXvJEzlZDrH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "outputId": "1c3f5128-f3fc-49bd-8e79-2ab4e0a0211f"
      },
      "source": [
        "te = TextExplainer(\n",
        "    sampler=sampler,\n",
        "    position_dependent=True,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "te.fit(text, predict_func)\n",
        "\n",
        "te.explain_prediction(\n",
        "    target_names=list(explainer_generator.idx2tag.values()),\n",
        "    top_targets=3\n",
        ")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        \n",
              "    \n",
              "        \n",
              "        \n",
              "    \n",
              "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
              "            <b>\n",
              "    \n",
              "        y=I-per\n",
              "    \n",
              "</b>\n",
              "\n",
              "    \n",
              "    (probability <b>0.969</b>, score <b>3.578</b>)\n",
              "\n",
              "top features\n",
              "        </p>\n",
              "    \n",
              "    <table class=\"eli5-weights\"\n",
              "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
              "        <thead>\n",
              "        <tr style=\"border: none;\">\n",
              "            \n",
              "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
              "                    Contribution<sup>?</sup>\n",
              "                </th>\n",
              "            \n",
              "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "            \n",
              "        </tr>\n",
              "        </thead>\n",
              "        <tbody>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +3.953\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        Highlighted in text (sum)\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "        \n",
              "\n",
              "        \n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 96.15%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -0.375\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        &lt;BIAS&gt;\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "\n",
              "        </tbody>\n",
              "    </table>\n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n",
              "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
              "        <span style=\"background-color: hsl(0, 100.00%, 89.00%); opacity: 0.83\" title=\"-0.471\">Nigeria</span><span style=\"opacity: 0.80\"> &#x27;</span><span style=\"background-color: hsl(0, 100.00%, 86.86%); opacity: 0.84\" title=\"-0.608\">s</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 61.09%); opacity: 0.99\" title=\"2.868\">President</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.35%); opacity: 0.80\" title=\"0.031\">Olusegun</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 85.89%); opacity: 0.85\" title=\"0.673\">Obasanjo</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 79.57%); opacity: 0.88\" title=\"1.142\">expressed</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.32%); opacity: 0.81\" title=\"0.183\">his</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.67%); opacity: 0.81\" title=\"0.086\">condolences</span><span style=\"opacity: 0.80\"> , noting the late </span><span style=\"background-color: hsl(0, 100.00%, 97.79%); opacity: 0.80\" title=\"-0.048\">pontiff</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 99.08%); opacity: 0.80\" title=\"0.014\">promoted</span><span style=\"opacity: 0.80\"> religious tolerance </span><span style=\"background-color: hsl(120, 100.00%, 98.04%); opacity: 0.80\" title=\"0.040\">and</span><span style=\"opacity: 0.80\"> democracy </span><span style=\"background-color: hsl(120, 100.00%, 97.92%); opacity: 0.80\" title=\"0.044\">in</span><span style=\"opacity: 0.80\"> the West African nation .</span>\n",
              "    </p>\n",
              "\n",
              "    \n",
              "        \n",
              "    \n",
              "        \n",
              "        \n",
              "    \n",
              "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
              "            <b>\n",
              "    \n",
              "        y=I-org\n",
              "    \n",
              "</b>\n",
              "\n",
              "    \n",
              "    (probability <b>0.010</b>, score <b>-4.573</b>)\n",
              "\n",
              "top features\n",
              "        </p>\n",
              "    \n",
              "    <table class=\"eli5-weights\"\n",
              "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
              "        <thead>\n",
              "        <tr style=\"border: none;\">\n",
              "            \n",
              "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
              "                    Contribution<sup>?</sup>\n",
              "                </th>\n",
              "            \n",
              "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "            \n",
              "        </tr>\n",
              "        </thead>\n",
              "        <tbody>\n",
              "        \n",
              "        \n",
              "\n",
              "        \n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 90.10%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -1.448\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        &lt;BIAS&gt;\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 83.04%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -3.125\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        Highlighted in text (sum)\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "\n",
              "        </tbody>\n",
              "    </table>\n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n",
              "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
              "        <span style=\"background-color: hsl(120, 100.00%, 88.17%); opacity: 0.84\" title=\"0.524\">Nigeria</span><span style=\"opacity: 0.80\"> &#x27;</span><span style=\"background-color: hsl(120, 100.00%, 92.12%); opacity: 0.82\" title=\"0.293\">s</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 60.00%); opacity: 1.00\" title=\"-2.983\">President</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.86%); opacity: 0.81\" title=\"-0.079\">Olusegun</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.01%); opacity: 0.82\" title=\"0.354\">Obasanjo</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 89.01%); opacity: 0.83\" title=\"-0.471\">expressed</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.25%); opacity: 0.82\" title=\"-0.286\">his</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.48%); opacity: 0.81\" title=\"-0.092\">condolences</span><span style=\"opacity: 0.80\"> , </span><span style=\"background-color: hsl(0, 100.00%, 98.45%); opacity: 0.80\" title=\"-0.029\">noting</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 99.10%); opacity: 0.80\" title=\"-0.013\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.80%); opacity: 0.80\" title=\"-0.020\">late</span><span style=\"opacity: 0.80\"> pontiff </span><span style=\"background-color: hsl(0, 100.00%, 97.97%); opacity: 0.80\" title=\"-0.042\">promoted</span><span style=\"opacity: 0.80\"> religious tolerance </span><span style=\"background-color: hsl(0, 100.00%, 98.21%); opacity: 0.80\" title=\"-0.035\">and</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.93%); opacity: 0.80\" title=\"-0.043\">democracy</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.43%); opacity: 0.80\" title=\"-0.029\">in</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.38%); opacity: 0.80\" title=\"-0.031\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.37%); opacity: 0.81\" title=\"-0.097\">West</span><span style=\"opacity: 0.80\"> African nation .</span>\n",
              "    </p>\n",
              "\n",
              "    \n",
              "        \n",
              "    \n",
              "        \n",
              "        \n",
              "    \n",
              "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
              "            <b>\n",
              "    \n",
              "        y=B-per\n",
              "    \n",
              "</b>\n",
              "\n",
              "    \n",
              "    (probability <b>0.006</b>, score <b>-5.127</b>)\n",
              "\n",
              "top features\n",
              "        </p>\n",
              "    \n",
              "    <table class=\"eli5-weights\"\n",
              "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
              "        <thead>\n",
              "        <tr style=\"border: none;\">\n",
              "            \n",
              "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
              "                    Contribution<sup>?</sup>\n",
              "                </th>\n",
              "            \n",
              "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "            \n",
              "        </tr>\n",
              "        </thead>\n",
              "        <tbody>\n",
              "        \n",
              "        \n",
              "\n",
              "        \n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 86.43%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -2.271\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        &lt;BIAS&gt;\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 84.07%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -2.856\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        Highlighted in text (sum)\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "\n",
              "        </tbody>\n",
              "    </table>\n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n",
              "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
              "        <span style=\"background-color: hsl(0, 100.00%, 95.19%); opacity: 0.81\" title=\"-0.145\">Nigeria</span><span style=\"opacity: 0.80\"> &#x27;</span><span style=\"background-color: hsl(0, 100.00%, 97.41%); opacity: 0.80\" title=\"-0.060\">s</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 74.03%); opacity: 0.91\" title=\"-1.609\">President</span><span style=\"opacity: 0.80\"> Olusegun </span><span style=\"background-color: hsl(120, 100.00%, 95.94%); opacity: 0.81\" title=\"0.114\">Obasanjo</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 86.43%); opacity: 0.84\" title=\"-0.637\">expressed</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.34%); opacity: 0.82\" title=\"-0.281\">his</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.02%); opacity: 0.80\" title=\"-0.041\">condolences</span><span style=\"opacity: 0.80\"> , </span><span style=\"background-color: hsl(0, 100.00%, 96.22%); opacity: 0.81\" title=\"-0.103\">noting</span><span style=\"opacity: 0.80\"> the </span><span style=\"background-color: hsl(0, 100.00%, 97.63%); opacity: 0.80\" title=\"-0.053\">late</span><span style=\"opacity: 0.80\"> pontiff </span><span style=\"background-color: hsl(0, 100.00%, 99.75%); opacity: 0.80\" title=\"-0.002\">promoted</span><span style=\"opacity: 0.80\"> religious tolerance and </span><span style=\"background-color: hsl(120, 100.00%, 97.60%); opacity: 0.80\" title=\"0.054\">democracy</span><span style=\"opacity: 0.80\"> in </span><span style=\"background-color: hsl(0, 100.00%, 98.43%); opacity: 0.80\" title=\"-0.029\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.28%); opacity: 0.80\" title=\"-0.064\">West</span><span style=\"opacity: 0.80\"> African nation .</span>\n",
              "    </p>\n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "Explanation(estimator=\"SGDClassifier(alpha=0.001, average=False, class_weight=None,\\n              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\\n              l1_ratio=0.15, learning_rate='optimal', loss='log', max_iter=1000,\\n              n_iter_no_change=5, n_jobs=None, penalty='elasticnet',\\n              power_t=0.5,\\n              random_state=<mtrand.RandomState object at 0x7f737dafa120>,\\n              shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0,\\n              warm_start=False)\", description=None, error=None, method='linear model', is_regression=False, targets=[TargetExplanation(target='I-per', feature_weights=FeatureWeights(pos=[FeatureWeight(feature='[2] President', weight=2.86761644633491, std=None, value=1.0), FeatureWeight(feature='[5] expressed', weight=1.1420026690620475, std=None, value=1.0), FeatureWeight(feature='[4] Obasanjo', weight=0.6733353904785359, std=None, value=1.0), FeatureWeight(feature='[6] his', weight=0.18337585616181237, std=None, value=1.0), FeatureWeight(feature='[7] condolences', weight=0.08561203718529581, std=None, value=1.0), FeatureWeight(feature='[17] in', weight=0.043560976273456065, std=None, value=1.0), FeatureWeight(feature='[15] and', weight=0.04015168839885265, std=None, value=1.0), FeatureWeight(feature='[3] Olusegun', weight=0.03139560848927649, std=None, value=1.0), FeatureWeight(feature='[12] promoted', weight=0.013656223142549632, std=None, value=1.0)], neg=[FeatureWeight(feature='[1] s', weight=-0.6083099919086711, std=None, value=1.0), FeatureWeight(feature='[0] Nigeria', weight=-0.47144577653237696, std=None, value=1.0), FeatureWeight(feature='<BIAS>', weight=-0.3752031516646971, std=None, value=1.0), FeatureWeight(feature='[11] pontiff', weight=-0.04760956973257726, std=None, value=1.0)], pos_remaining=0, neg_remaining=0), proba=0.96927705807074, score=3.578138405688414, weighted_spans=WeightedSpans(docs_weighted_spans=[DocWeightedSpans(document=\"Nigeria 's President Olusegun Obasanjo expressed his condolences , noting the late pontiff promoted religious tolerance and democracy in the West African nation .\", spans=[('Nigeria', [(0, 7)], -0.47144577653237696), ('s', [(9, 10)], -0.6083099919086711), ('President', [(11, 20)], 2.86761644633491), ('Olusegun', [(21, 29)], 0.03139560848927649), ('Obasanjo', [(30, 38)], 0.6733353904785359), ('expressed', [(39, 48)], 1.1420026690620475), ('his', [(49, 52)], 0.18337585616181237), ('condolences', [(53, 64)], 0.08561203718529581), ('pontiff', [(83, 90)], -0.04760956973257726), ('promoted', [(91, 99)], 0.013656223142549632), ('and', [(120, 123)], 0.04015168839885265), ('in', [(134, 136)], 0.043560976273456065)], preserve_density=False, vec_name=None)], other=FeatureWeights(pos=[FeatureWeight(feature=<FormattedFeatureName 'Highlighted in text (sum)'>, weight=3.953341557353111, std=None, value=None)], neg=[FeatureWeight(feature='<BIAS>', weight=-0.3752031516646971, std=None, value=1.0)], pos_remaining=0, neg_remaining=0)), heatmap=None), TargetExplanation(target='I-org', feature_weights=FeatureWeights(pos=[FeatureWeight(feature='[0] Nigeria', weight=0.523593327624631, std=None, value=1.0), FeatureWeight(feature='[4] Obasanjo', weight=0.3535456411072404, std=None, value=1.0), FeatureWeight(feature='[1] s', weight=0.2927320923886197, std=None, value=1.0)], neg=[FeatureWeight(feature='[2] President', weight=-2.9828843041065554, std=None, value=1.0), FeatureWeight(feature='<BIAS>', weight=-1.4481618502090499, std=None, value=1.0), FeatureWeight(feature='[5] expressed', weight=-0.47134344120401467, std=None, value=1.0), FeatureWeight(feature='[6] his', weight=-0.2862690240968326, std=None, value=1.0), FeatureWeight(feature='[19] West', weight=-0.0967680656945793, std=None, value=1.0), FeatureWeight(feature='[7] condolences', weight=-0.09247106009783232, std=None, value=1.0), FeatureWeight(feature='[3] Olusegun', weight=-0.07851904310991183, std=None, value=1.0), FeatureWeight(feature='[18] the', weight=-0.061285740546892745, std=None, value=1.0), FeatureWeight(feature='[16] democracy', weight=-0.04332223712636124, std=None, value=1.0), FeatureWeight(feature='[12] promoted', weight=-0.042198628796675915, std=None, value=1.0), FeatureWeight(feature='[15] and', weight=-0.035322305634108646, std=None, value=1.0), FeatureWeight(feature='[17] in', weight=-0.02931400609080078, std=None, value=1.0), FeatureWeight(feature='[8] noting', weight=-0.02877106962966931, std=None, value=1.0), FeatureWeight(feature='[9] the', weight=-0.026291109033335546, std=None, value=1.0), FeatureWeight(feature='[10] late', weight=-0.0198125822742492, std=None, value=1.0)], pos_remaining=0, neg_remaining=0), proba=0.010185411905497035, score=-4.572863406530378, weighted_spans=WeightedSpans(docs_weighted_spans=[DocWeightedSpans(document=\"Nigeria 's President Olusegun Obasanjo expressed his condolences , noting the late pontiff promoted religious tolerance and democracy in the West African nation .\", spans=[('Nigeria', [(0, 7)], 0.523593327624631), ('s', [(9, 10)], 0.2927320923886197), ('President', [(11, 20)], -2.9828843041065554), ('Olusegun', [(21, 29)], -0.07851904310991183), ('Obasanjo', [(30, 38)], 0.3535456411072404), ('expressed', [(39, 48)], -0.47134344120401467), ('his', [(49, 52)], -0.2862690240968326), ('condolences', [(53, 64)], -0.09247106009783232), ('noting', [(67, 73)], -0.02877106962966931), ('the', [(74, 77)], -0.026291109033335546), ('late', [(78, 82)], -0.0198125822742492), ('promoted', [(91, 99)], -0.042198628796675915), ('and', [(120, 123)], -0.035322305634108646), ('democracy', [(124, 133)], -0.04332223712636124), ('in', [(134, 136)], -0.02931400609080078), ('the', [(137, 140)], -0.061285740546892745), ('West', [(141, 145)], -0.0967680656945793)], preserve_density=False, vec_name=None)], other=FeatureWeights(pos=[], neg=[FeatureWeight(feature=<FormattedFeatureName 'Highlighted in text (sum)'>, weight=-3.1247015563213276, std=None, value=None), FeatureWeight(feature='<BIAS>', weight=-1.4481618502090499, std=None, value=1.0)], pos_remaining=0, neg_remaining=0)), heatmap=None), TargetExplanation(target='B-per', feature_weights=FeatureWeights(pos=[FeatureWeight(feature='[4] Obasanjo', weight=0.11368252202085632, std=None, value=1.0), FeatureWeight(feature='[16] democracy', weight=0.05354304701343281, std=None, value=1.0)], neg=[FeatureWeight(feature='<BIAS>', weight=-2.271380307317229, std=None, value=1.0), FeatureWeight(feature='[2] President', weight=-1.6093928621221008, std=None, value=1.0), FeatureWeight(feature='[5] expressed', weight=-0.6368620681811783, std=None, value=1.0), FeatureWeight(feature='[6] his', weight=-0.28128508322736057, std=None, value=1.0), FeatureWeight(feature='[0] Nigeria', weight=-0.14456251141215254, std=None, value=1.0), FeatureWeight(feature='[8] noting', weight=-0.10253032838643424, std=None, value=1.0), FeatureWeight(feature='[19] West', weight=-0.06394303890838225, std=None, value=1.0), FeatureWeight(feature='[1] s', weight=-0.05977201292254027, std=None, value=1.0), FeatureWeight(feature='[10] late', weight=-0.05260380724786101, std=None, value=1.0), FeatureWeight(feature='[7] condolences', weight=-0.04064045321844723, std=None, value=1.0), FeatureWeight(feature='[18] the', weight=-0.029246575618274102, std=None, value=1.0), FeatureWeight(feature='[12] promoted', weight=-0.0021275616310198918, std=None, value=1.0)], pos_remaining=0, neg_remaining=0), proba=0.005877068850603085, score=-5.127121041158691, weighted_spans=WeightedSpans(docs_weighted_spans=[DocWeightedSpans(document=\"Nigeria 's President Olusegun Obasanjo expressed his condolences , noting the late pontiff promoted religious tolerance and democracy in the West African nation .\", spans=[('Nigeria', [(0, 7)], -0.14456251141215254), ('s', [(9, 10)], -0.05977201292254027), ('President', [(11, 20)], -1.6093928621221008), ('Obasanjo', [(30, 38)], 0.11368252202085632), ('expressed', [(39, 48)], -0.6368620681811783), ('his', [(49, 52)], -0.28128508322736057), ('condolences', [(53, 64)], -0.04064045321844723), ('noting', [(67, 73)], -0.10253032838643424), ('late', [(78, 82)], -0.05260380724786101), ('promoted', [(91, 99)], -0.0021275616310198918), ('democracy', [(124, 133)], 0.05354304701343281), ('the', [(137, 140)], -0.029246575618274102), ('West', [(141, 145)], -0.06394303890838225)], preserve_density=False, vec_name=None)], other=FeatureWeights(pos=[], neg=[FeatureWeight(feature=<FormattedFeatureName 'Highlighted in text (sum)'>, weight=-2.855740733841462, std=None, value=None), FeatureWeight(feature='<BIAS>', weight=-2.271380307317229, std=None, value=1.0)], pos_remaining=0, neg_remaining=0)), heatmap=None)], feature_importances=None, decision_tree=None, highlight_spaces=None, transition_features=None, image=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XmcuSI1ZX0V",
        "colab_type": "text"
      },
      "source": [
        "Very nice! As expected, the model predicted I-per for a later part of a person name. The word President is a strong indicator that the following word is part of a name. This indicates, that in the dataset, President is often part of the annotation of a Person."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lc3IS8oAZPPm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}