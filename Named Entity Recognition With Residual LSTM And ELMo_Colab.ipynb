{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "tf20",
      "language": "python",
      "name": "tf20"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Named Entity Recognition With Residual LSTM And ELMo.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8MjvLHE0Fyn",
        "colab_type": "text"
      },
      "source": [
        "We will use a residual LSTM network together with ELMo embeddings [1], developed at Allen NLP. You will learn how to wrap a tensorflow hub pre-trained model to work with keras. The resulting model with give you state-of-the-art performance on the named entity recognition task.\n",
        "\n",
        "### What are ELMo embeddings?\n",
        "ELMo embeddings are embeddings from a language model trained on the 1 Billion Word Benchmark and the pretrained version is availiable on tensorflow hub. Unlike most widely used word embeddings, ELMo word representations are functions of the entire input sentence. They are computed on top of two-layer bidirectional language model with character convolutions, as a linear function of the internal network states. Concretely, ELMos use a pre-trained, multi-layer, bi-directional, LSTM-based language model and extract the hidden state of each layer for the input sequence of words. Then, they compute a weighted sum of those hidden states to obtain an embedding for each word. The weight of each hidden state is task-dependent and is learned. ELMo improves the performance of models across a wide range of tasks, spanning from question answering and sentiment analysis to named entity recognition. This setup allows us to do semi-supervised learning, where the biLM is pre-trained at a large scale and easily incorporated into a wide range of existing neural NLP architectures.\n",
        "\n",
        "I suggest having a look at the great paper “Deep contextualized word representations” https://arxiv.org/pdf/1802.05365.pdf."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KsAHp6dy0Fyu",
        "colab_type": "text"
      },
      "source": [
        "### Data preperation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwSgrFQ_0YhJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d74aff27-69cc-4928-b399-8d58f483859f"
      },
      "source": [
        "import os\n",
        "from urllib.request import urlretrieve\n",
        "import zipfile\n",
        "import glob\n",
        "\n",
        "if not os.path.exists('data'):\n",
        "    os.makedirs('data')\n",
        "    \n",
        "# Download data\n",
        "url ='https://storage.googleapis.com/kaggle-datasets/1014/4361/entity-annotated-corpus.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1567749367&Signature=X%2FhIcHdTAMR%2F1SVt%2F3uiJN4deGEMy82PuQaEuezIVz1AahALWq47CS1m06eSlYClHYIc5SvmLCid6pb%2FzRr%2BTg1E2ogs2oi85EdqpUXVgk9G0boIFMIhZGSfUe%2Bg8eWjjGSGEp%2FKZbxd75myX3BgHInMYnr5IYl%2FOTbk%2BLvEpDbzIApolLprkeFryaX19yiw%2B9r0KfjdraczmSK0UTbXAaNYwYHjvX3CFW6ExYJwzT0zGK0i5PAYcFxp68hwTMrGJN6jiFJqMrqHpO6tR4DyIYd1pn79JwpbpAiE2SukZK1vddD3SNAOVV9VlBBakvcNZLCxUaL3%2BtncYWpmCgtBog%3D%3D'\n",
        "\n",
        "urlretrieve(url, 'data/kaggle_ner.zip')\n",
        "\n",
        "with zipfile.ZipFile('data/kaggle_ner.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('data/')\n",
        "    \n",
        "import glob\n",
        "\n",
        "glob.glob('data/*')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['data/ner_dataset.csv', 'data/kaggle_ner.zip', 'data/ner.csv']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZRvkQcG0Fyx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd    \n",
        "import numpy as np\n",
        "\n",
        "data = pd.read_csv(\"data/ner_dataset.csv\", encoding=\"latin1\")\n",
        "data = data.fillna(method=\"ffill\")\n",
        "\n",
        "class SentenceGetter(object):\n",
        "    def __init__(self, data):\n",
        "        self.n_sent = 1\n",
        "        self.data = data\n",
        "        self.empty = False\n",
        "        agg_func = lambda s: [(w, p, t) for w, p, t in zip(s[\"Word\"].values.tolist(),\n",
        "                                                           s[\"POS\"].values.tolist(),\n",
        "                                                           s[\"Tag\"].values.tolist())]\n",
        "        self.grouped = self.data.groupby(\"Sentence #\").apply(agg_func)\n",
        "        self.sentences = [s for s in self.grouped]\n",
        "    \n",
        "    def get_next(self):\n",
        "        try:\n",
        "            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n",
        "            self.n_sent += 1\n",
        "            return s\n",
        "        except:\n",
        "            return None\n",
        "        \n",
        "getter = SentenceGetter(data)\n",
        "sentences = getter.sentences\n",
        "\n",
        "max_len = 50\n",
        "max_len_char = 10\n",
        "\n",
        "words = list(set(data[\"Word\"].values))\n",
        "words.append(\"ENDPAD\")\n",
        "n_words = len(words)\n",
        "\n",
        "tags = list(set(data[\"Tag\"].values))\n",
        "n_tags = len(tags); n_tags\n",
        "tag2idx = {t: i for i, t in enumerate(tags)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sO6D7fa60Fy-",
        "colab_type": "text"
      },
      "source": [
        "To apply the EMLo embedding from tensorflow hub, we have to use strings as input. So we take the tokenized sentences and pad them to the desired length."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8j2j-bfp0FzE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "outputId": "5fe8bf7c-0997-4197-c51a-228450f79a28"
      },
      "source": [
        "X = [[w[0] for w in s] for s in sentences]\n",
        "\n",
        "new_X = []\n",
        "for seq in X:\n",
        "    new_seq = []\n",
        "    for i in range(max_len):\n",
        "        try:\n",
        "            new_seq.append(seq[i])\n",
        "        except:\n",
        "            new_seq.append(\"__PAD__\")\n",
        "    new_X.append(new_seq)\n",
        "X = new_X\n",
        "X[1]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Iranian',\n",
              " 'officials',\n",
              " 'say',\n",
              " 'they',\n",
              " 'expect',\n",
              " 'to',\n",
              " 'get',\n",
              " 'access',\n",
              " 'to',\n",
              " 'sealed',\n",
              " 'sensitive',\n",
              " 'parts',\n",
              " 'of',\n",
              " 'the',\n",
              " 'plant',\n",
              " 'Wednesday',\n",
              " ',',\n",
              " 'after',\n",
              " 'an',\n",
              " 'IAEA',\n",
              " 'surveillance',\n",
              " 'system',\n",
              " 'begins',\n",
              " 'functioning',\n",
              " '.',\n",
              " '__PAD__',\n",
              " '__PAD__',\n",
              " '__PAD__',\n",
              " '__PAD__',\n",
              " '__PAD__',\n",
              " '__PAD__',\n",
              " '__PAD__',\n",
              " '__PAD__',\n",
              " '__PAD__',\n",
              " '__PAD__',\n",
              " '__PAD__',\n",
              " '__PAD__',\n",
              " '__PAD__',\n",
              " '__PAD__',\n",
              " '__PAD__',\n",
              " '__PAD__',\n",
              " '__PAD__',\n",
              " '__PAD__',\n",
              " '__PAD__',\n",
              " '__PAD__',\n",
              " '__PAD__',\n",
              " '__PAD__',\n",
              " '__PAD__',\n",
              " '__PAD__',\n",
              " '__PAD__']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifJGPF8g0FzR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "cabd045b-6423-457c-80e5-acbbdb52092f"
      },
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "y = [[tag2idx[w[2]] for w in s] for s in sentences]\n",
        "y = pad_sequences(maxlen=max_len, sequences=y, padding=\"post\", value=tag2idx[\"O\"])\n",
        "y[1]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([12,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  0,\n",
              "        0,  0, 13,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "      dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yZ2oC9z0Fzb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.1, random_state=2018)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlR18nKx0Fze",
        "colab_type": "text"
      },
      "source": [
        "### The ELMo residual LSTM model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_wY4SzZ0Fzj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a2f561a9-8cca-4d5a-a13f-91e7ebc8a94f"
      },
      "source": [
        "# !pip install 'tensorflow_hub==0.4.0'\n",
        "\n",
        "# %tensorflow_version only exists in Colab.\n",
        "%tensorflow_version 2.x\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.framework.ops import disable_eager_execution\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "disable_eager_execution()\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "sess = tf.compat.v1.Session()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow is already loaded. Please restart the runtime to change versions.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlPS3Cnl0Fzo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import backend as K\n",
        "\n",
        "class ElmoEmbeddingLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        self.dimensions = 1024\n",
        "        self.trainable = True\n",
        "        super(ElmoEmbeddingLayer, self).__init__(**kwargs)\n",
        "        \n",
        "    def build(self, input_shape):\n",
        "        self.elmo = hub.Module('https://tfhub.dev/google/elmo/2', trainable=self.trainable, name=\"{}_module\".format(self.name))\n",
        "        self._trainable_weights += tf.compat.v1.trainable_variables(scope=\"^{}_module/.*\".format(self.name))\n",
        "        super(ElmoEmbeddingLayer, self).build(input_shape)\n",
        "            \n",
        "    def call(self, x, mask=None):\n",
        "        result = self.elmo(inputs={\n",
        "                            \"tokens\": tf.squeeze(tf.cast(x, tf.string)),\n",
        "                            \"sequence_len\": tf.constant(batch_size*[max_len])\n",
        "                      },\n",
        "                      signature=\"tokens\",\n",
        "                      as_dict=True)[\"elmo\"]\n",
        "        return result\n",
        "    \n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        return K.not_equal(inputs, '__PAD__')\n",
        "    \n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return (input_shape[0], self.dimensions)\n",
        "      \n",
        "      \n",
        "      \n",
        "elmo_model = hub.Module(\"https://tfhub.dev/google/elmo/2\", trainable=True)\n",
        "sess.run(tf.global_variables_initializer())\n",
        "sess.run(tf.tables_initializer())\n",
        "\n",
        "def ElmoEmbedding(x):\n",
        "    return elmo_model(inputs={\n",
        "                            \"tokens\": tf.squeeze(tf.cast(x, tf.string)),\n",
        "                            \"sequence_len\": tf.constant(batch_size*[max_len])\n",
        "                      },\n",
        "                      signature=\"tokens\",\n",
        "                      as_dict=True)[\"elmo\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZsToQQU0Fz7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 640
        },
        "outputId": "4aa14d29-d782-48f0-a8b7-b985abaf10ed"
      },
      "source": [
        "from tensorflow.keras import Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Conv1D, Lambda\n",
        "from tensorflow.keras.layers import Bidirectional, concatenate, SpatialDropout1D, GlobalMaxPooling1D, add\n",
        "\n",
        "input_text = Input(shape=(max_len,), dtype=tf.string)\n",
        "embedding = Lambda(ElmoEmbedding, output_shape=(None, max_len, 1024))(input_text)\n",
        "#embedding = ElmoEmbeddingLayer()(input_text)\n",
        "x = Bidirectional(LSTM(units=512, return_sequences=True,\n",
        "                       recurrent_dropout=0.2, dropout=0.2))(embedding)\n",
        "x_rnn = Bidirectional(LSTM(units=512, return_sequences=True,\n",
        "                           recurrent_dropout=0.2, dropout=0.2))(x)\n",
        "x = add([x, x_rnn])  # residual connection to the first biLSTM\n",
        "out = TimeDistributed(Dense(n_tags, activation=\"softmax\"))(x)\n",
        "\n",
        "model = Model(input_text, out)\n",
        "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0905 09:01:14.741072 140377373177728 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0905 09:01:14.748462 140377373177728 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0905 09:01:14.749565 140377373177728 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0905 09:01:14.750576 140377373177728 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 50)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lambda (Lambda)                 (32, None, 1024)     0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional (Bidirectional)   (32, None, 1024)     6295552     lambda[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_1 (Bidirectional) (32, None, 1024)     6295552     bidirectional[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (32, None, 1024)     0           bidirectional[0][0]              \n",
            "                                                                 bidirectional_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed (TimeDistribut (None, None, 17)     17425       add[0][0]                        \n",
            "==================================================================================================\n",
            "Total params: 12,608,529\n",
            "Trainable params: 12,608,529\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzpzdRCb0Fz_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_tr, X_val = X_tr[:1213*batch_size], X_tr[-135*batch_size:]\n",
        "y_tr, y_val = y_tr[:1213*batch_size], y_tr[-135*batch_size:]\n",
        "y_tr = y_tr.reshape(y_tr.shape[0], y_tr.shape[1], 1)\n",
        "y_val = y_val.reshape(y_val.shape[0], y_val.shape[1], 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0f01bXQ0F0C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "49ada597-9625-4133-bb93-a8e87ae7298b"
      },
      "source": [
        "with sess:\n",
        "    sess.run(tf.compat.v1.global_variables_initializer())\n",
        "    sess.run(tf.compat.v1.tables_initializer())\n",
        "    history = model.fit(np.array(X_tr), y_tr, validation_data=(np.array(X_val), y_val),\n",
        "                        batch_size=batch_size, epochs=1, verbose=1)\n",
        "    \n",
        "    i = 19\n",
        "    p = model.predict(np.array(X_te[i:i+batch_size]))[0]\n",
        "    p = np.argmax(p, axis=-1)\n",
        "    print(\"{:15} {:5}: ({})\".format(\"Word\", \"Pred\", \"True\"))\n",
        "    print(\"=\"*30)\n",
        "    for w, true, pred in zip(X_te[i], y_te[i], p):\n",
        "        if w != \"__PAD__\":\n",
        "            print(\"{:15}:{:5} ({})\".format(w, tags[pred], tags[true]))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0905 09:01:17.656708 140377373177728 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 38816 samples, validate on 4320 samples\n",
            "38816/38816 [==============================] - 619s 16ms/sample - loss: 0.0624 - acc: 0.9820 - val_loss: 0.0463 - val_acc: 0.9857\n",
            "Word            Pred : (True)\n",
            "==============================\n",
            "Meanwhile      :O     (O)\n",
            ",              :O     (O)\n",
            "in             :O     (O)\n",
            "Belgrade       :B-geo (B-geo)\n",
            ",              :O     (O)\n",
            "Serbia         :B-geo (B-geo)\n",
            "'s             :O     (O)\n",
            "extreme        :O     (O)\n",
            "nationalist    :O     (O)\n",
            "Radical        :B-org (B-org)\n",
            "Party          :I-org (I-org)\n",
            "has            :O     (O)\n",
            "filed          :O     (O)\n",
            "a              :O     (O)\n",
            "motion         :O     (O)\n",
            "of             :O     (O)\n",
            "no-confidence  :O     (O)\n",
            "in             :O     (O)\n",
            "the            :O     (O)\n",
            "government     :O     (O)\n",
            "of             :O     (O)\n",
            "Prime          :B-per (B-per)\n",
            "Minister       :I-per (O)\n",
            "Vojislav       :B-per (B-per)\n",
            "Kostunica      :I-per (I-per)\n",
            "to             :O     (O)\n",
            "protest        :O     (O)\n",
            "the            :O     (O)\n",
            "extradition    :O     (O)\n",
            "of             :O     (O)\n",
            "11             :O     (O)\n",
            "suspects       :O     (O)\n",
            "to             :O     (O)\n",
            "the            :O     (O)\n",
            "court          :O     (O)\n",
            "since          :B-tim (B-tim)\n",
            "October        :I-tim (I-tim)\n",
            ".              :O     (O)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rN5K8u17pOkj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}